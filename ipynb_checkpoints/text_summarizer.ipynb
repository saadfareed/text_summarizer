{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import summarizer\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_perc(initial_text, summarized_text):\n",
    "    '''\n",
    "    The purpose of this function is to output a % associated to the length of the text which was reduced and summarized.\n",
    "    \n",
    "    args:\n",
    "        initial_text (str) : This variable holds the initial body of text passed throguh the model\n",
    "        summarized_text (str) : This holds the output text which was summarized by the model\n",
    "    \n",
    "    returns:\n",
    "        A percentage associated to how much from the initial text was summarized\n",
    "        \n",
    "    example:\n",
    "        summary_perc(initial_text = body, summarized_text = result)\n",
    "    '''\n",
    "    percentage = len(summarized_text) / len(initial_text)\n",
    "    return print('The initial text was reduced by : ', 1 - percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Pre Trained Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Clearly, the number of pieces of information that must be found and used for bauxite to become, say, the aluminum sheeting that forms the cas- ing of the printing press that produced the pages that you are now reading is staggeringly large. It is a number far larger than the mere one billion pieces of the jigsaw puzzle in my example.\n",
    "It’s foolish to expect any one person (or small group of people) to find all the pieces of information necessary for the production of aluminum sheeting (and for the production of fuselages for airliners, the production of oven foil, the production of soda cans ... the list is long).\n",
    "Not only is the mere finding of all the many pieces of information too difficult to entrust to a small group of people; so, too, is the task of putting these pieces together in a way that yields useful final products.\n",
    "Let’s now amend the example to make the jigsaw puzzle an even bet- ter metaphor for economic reality. Suppose that, unlike with regular jigsaw puzzles, each piece of this puzzle can be made to fit snugly and smoothly with any other piece. In this case, merely assembling all of the one billion puzzle pieces so that they fit together neatly is easy. But note that it is possible to create an unfathomably large number of scenes with these pieces.\n",
    "Trouble is, only a tiny handful of these scenes will please the human eye. Most of the scenes will be visual gibberish. The challenge is to arrange the pieces together so that the final result is a recognizable scene—say, of a field of sunflowers or of a bustling city street. Only if the scene is recognizable is the assembled puzzle valuable.\n",
    "Now imagine yourself standing alone before a gigantic table covered with these one billion puzzle pieces. What are the chances that you alone can put these pieces together so that the final result is a coherent visual image—a useful and valuable final result?\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(text, min_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clearly, the number of pieces of information that must be found and used for bauxite to become, say, the aluminum sheeting that forms the cas- ing of the printing press that produced the pages that you are now reading is staggeringly large. Trouble is, only a tiny handful of these scenes will please the human eye.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Summarized Text : Clearly, the number of pieces of information that must be found and used for bauxite to become, say, the aluminum sheeting that forms the cas- ing of the printing press that produced the pages that you are now reading is staggeringly large. Trouble is, only a tiny handful of these scenes will please the human eye.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The Summarized Text : {}'.format(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1892"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial text was reduced by :  0.8335095137420718\n"
     ]
    }
   ],
   "source": [
    "summary_perc(initial_text = text, summarized_text = result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../summarizer_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(filename)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
